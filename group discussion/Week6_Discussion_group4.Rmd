---
title: "Week 6 Discussion (Group)" 
author: "Group 4"
date: "`r Sys.Date()`"
output: pdf_document
fontsize: 11pt
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Week 6 | Discussion (Group) - Project Group 4

* General section:
  * What does a confidence interval tell us about a population parameter?
    * As a % how confident we have that at most X amount of people. 
  * If we have a 95% confidence interval of [2.5, 3.5] for a population mean, how should we interpret this interval?
    * 
  * How does changing the confidence level (e.g., from 90% to 99%) affect the width of the confidence interval? Why does this happen?
    * It would reduce/lower the width of the confidence interval. Why.....
  * How is the margin of error related to confidence intervals?
    * The margin of error is the mirror of a confidence interval. As confidence increases, the margin of error would decrease. 

* Real-life paper section: (DIVYA)
  * Find a research paper where confidence intervals are used to present findings. Use APA citations.
    * Lininger, M. R., & Riemann, B. L. (2016). Statistical primer for athletic trainers: Using confidence intervals and effect sizes to evaluate clinical meaningfulness. Journal of Athletic Training, 51(12), 1045–1048. https://doi.org/10.4085/1062-6050-51.12.14.
  * Analyze how well the confidence interval is explained in the report.
    * In the paper the concept of the confidence interval (CI) is explained very clearly and effectively, especially for readers in clinical and applied health fields. The authors begin by defining a CI as a “range of values within which the population value is believed to lie at a given level of statistical confidence”. They go beyond the mathematical definition by emphasizing its practical importance helping clinicians understand not only whether a treatment effect exists but also how precise that estimate is. The explanation is strengthened through a practical example involving ankle dorsiflexion range of motion (ROM), which demonstrates how the CI can help determine whether an observed difference is likely to be clinically meaningful. The authors illustrate that a narrow CI (e.g. 5°–8°) indicates a more precise and useful estimate, while a wide CI (e.g.1°–15°) leads to uncertainty and limited decision-making value. They also discuss factors influencing CI width, such as sample size, variability, and confidence level, and caution that even a 95% CI does not guarantee every patient will experience the same result. Overall, the report explains confidence intervals in a thorough, logical, and clinically relevant manner, making a complex statistical concept accessible and meaningful for practitioners.
  * How does the variability of the data impact the confidence interval?
    * According to the paper, the variability of the data has a direct influence on the width of the confidence interval (CI). When there is greater variability in the sample data meaning that participants respond differently to the treatment—the CI becomes wider, indicating less precision in estimating the true population effect. This happens because inconsistent responses among individuals make it harder to determine the actual impact of the intervention. On the other hand, lower variability results in a narrower CI, providing a more precise and reliable estimate of the true effect. The authors state that “variability within the sample indicates that the treatment effect was not consistent among study participants, which can occur when inclusion or exclusion criteria are broad”. Therefore, reducing variability in a study helps produce narrower confidence intervals and allows clinicians to interpret results with greater confidence in their accuracy.
  * What might happen if the confidence interval is too wide to provide meaningful insights?
    * The variability of the data directly affects the width and precision of the confidence interval (CI). According to the paper, when there is greater variability among study participants meaning that individuals respond differently to the intervention the confidence interval becomes wider. This happens because inconsistent responses make it harder to estimate the true population effect with precision. In contrast, when data variability is low, meaning participants respond more uniformly, the CI becomes narrower and provides a more precise estimate of the treatment’s effect. The authors explain that variability within the sample indicates that the treatment effect was not consistent among study participants, which can occur when inclusion or exclusion criteria are broad. They note that wide intervals caused by high variability make it difficult for clinicians to be confident about the actual benefit of an intervention. Thus, minimizing variability through careful study design and participant selection leads to narrower, more useful confidence intervals for clinical decision-making.

* Real-life case study section: (NICK) 
  * Explore a real-life case study where biased sampling led to incorrect conclusions. Use APA citations.
  * What were the consequences, and how could the issue have been avoided?
  * Why is it important to use proper sampling methods in statistics?
  * Discuss the risks of bias in sampling.

# Real-life Case Study Section  

## 1. Explore a real-life case study where biased sampling led to incorrect conclusions

A famous historical example of biased sampling occurred during the 1936 U.S. presidential election, when *The Literary Digest* magazine conducted one of the largest opinion polls in history. The magazine sent out more than ten million questionnaires to predict whether Franklin D. Roosevelt or Alf Landon would win the presidency. Approximately 2.4 million responses were received, and the poll predicted a decisive victory for Landon. However, the actual election results were the opposite — Roosevelt won in a landslide.

The failure of this prediction stemmed from selection bias and nonresponse bias. The sample was drawn from automobile registration lists, telephone directories, and magazine subscription records. During the Great Depression, people who owned cars or telephones tended to be wealthier and thus more likely to vote Republican. On top of that, individuals who responded voluntarily were not representative of the overall population, adding to the distortion (*Squire, 1988*). This case demonstrates that a massive sample size cannot overcome a fundamentally biased sampling.


## 2. What were the consequences, and how could the issue have been avoided?

The poll’s inaccuracy had serious consequences for both the magazine’s credibility and the public’s trust in polling. *The Literary Digest*’s reputation was completely damaged, leading to a decline in readership and eventual closure. In contrast, George Gallup, who used a smaller but scientifically randomized sample, correctly predicted Roosevelt’s victory. This event marked a turning point in modern statistics and public opinion research, proving that representation matters more than just sample size (*Bryson, 1976*).

The issue could have been avoided through probability sampling instead of convenience sampling. Specifically:

- Drawing a random sample that represented various socioeconomic groups.  
- Using stratified sampling to ensure proportional representation from urban and rural populations.  
- Conducting follow-ups to reduce nonresponse bias.


## 3. Why is it important to use proper sampling methods in statistics?

Proper sampling methods are essential because statistical inferences depend on how well a sample represents the population. Without representation, even precise calculations like means, confidence intervals, and margins of error can be misleading. Sound sampling allows researchers to generalize findings with confidence and minimize systematic error. The *Literary Digest* poll demonstrated that biased data collection can lead to false conclusions, even when millions of data points are available. Good sampling design is thus the foundation of reliable data analysis.


## 4. Discuss the risks of bias in sampling  

Sampling bias can arise in multiple ways:

- **Selection Bias:** Occurs when some groups are more likely to be included than others. For example, in 1936, only wealthier Americans were sampled because they owned telephones or cars.  
- **Nonresponse Bias:** Individuals who fail to respond may differ systematically from those who do; in the Digest poll, low-income voters were underrepresented.  
- **Measurement Bias:** Poorly designed questions or data collection methods can influence responses.  
- **Convenience Bias:** Relying on easily accessible participants rather than a random cross-section of the population.  

Each of these biases distorts statistical estimates and weakens the validity of conclusions. Recognizing and minimizing bias ensures that results are accurate, generalizable, and trustworthy.


## References (APA 7th Edition)

Bryson, L. (1976). *The Literary Digest poll: Making of a statistical myth*. *Public Opinion Quarterly, 40*, 431–436. https://doi.org/10.1086/268319  

Squire, P. (1988). *Why the 1936 Literary Digest poll failed*. *Public Opinion Quarterly, 52*, 125–133. https://doi.org/10.1086/269082

* Group dataset section:
  * Describe one of your datasets and research question(s). Use APA citations (where necessary).
  * Select a key variable from this dataset. Describe the variable.
  * Calculate the 95% confidence interval for the mean of the variable.
  * Discuss how the intervals vary based on changes in sample size, variability, and confidence levels.
  * Discuss how sample size affects the confidence interval width.
  * Is it possible to have a narrow confidence interval with a small sample size?
  * Reflect on the accuracy of using small versus large samples and what role statistical sampling plays in ensuring reliable results.
